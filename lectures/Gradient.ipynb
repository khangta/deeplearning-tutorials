{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div style=\"text-align: center; font-size: 35px\">\n",
    "    <b>\n",
    "    Gradient descent\n",
    "    </b>\n",
    "</div>\n",
    "<br/> <br/> <br/>\n",
    "\n",
    "Chào các bạn, trong [bài viết trước](khanhxnguyen.com/deep-learning-4/), mình đã giới thiệu sơ lược về cách thức huấn luyện một model deep learning. \n",
    "\n",
    "Huấn luyện (training) gồm hai giai đoạn, forward và backward. Trong bước forward, ta tính loss function dựa vào dự đoán của model và label thật. Trong bước backward, ta tính gradient (đạo hàm) theo parameter $\\theta$ của model, và cập nhật chúng theo quy tắc:\n",
    "$$ \\theta_{new} = \\theta_{old} - \\alpha \\nabla_{\\theta} L$$ với $\\alpha$ là learning rate và $\\nabla_{\\theta}$ ký hiệu đạo hàm theo $\\theta$ của loss function $L$.\n",
    "\n",
    "Nhưng tại sao lại làm như vậy trong bước forward? Bài học hôm nay sẽ trả lời cho câu hỏi đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mục đích của huấn luyện\n",
    "\n",
    "Mục đích của huấn luyện là tìm ra tham số $\\theta^*$ tối ưu sao cho tổng loss function trên training set là nhỏ nhất. Theo ngôn ngữ toán học,\n",
    "\n",
    "$$ \\theta^* = \\arg \\min_{\\theta} \\mathcal{L}(\\theta) = \\arg \\min_{\\theta} \\sum_{(x, y) \\in D_{train}} L(f_{\\theta}(x), y)$$ với $D_{train}$ là training set. \n",
    "\n",
    "Bài toán này là một dạng của **function optimization** (tối ưu hàm số). Ở đây vì $\\theta$ không có điều kiện gì ràng buộc nên được gọi là **unconstrained optimization**. \n",
    "\n",
    "Vì không có công thức trực tiếp cho $\\theta^*$, ta bắt buộc phải làm nhỏ dần $\\mathcal{L}(\\theta)$ qua nhiều bước. Ta bắt đầu với một $\\theta$ ngẫu nhiên, và tìm cách làm cho $\\theta$ càng ngày càng tiến gần tới $\\theta^*$. Cách làm như vậy được gọi là một **iterative method**. Mỗi lần forward và backward chính là một bước biến đổi $\\theta$ để làm $\\mathcal{L}(\\theta)$ nhỏ dần đi.\n",
    "\n",
    "Nếu ai đã quen thuộc với **binary search** thì sẽ nhận ra thuật toán này cũng mang tư tưởng tương tự. Binary search thực chất là một dạng đặc biệt của function optimization với hàm được tối ưu chính là giá trị tuyệt đối giữa dự đoán hiện tại và giá trị cần tìm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient \n",
    "\n",
    "Có rất nhiều phương pháp  để tối ưu hàm số. Cách phương pháp sử dụng gradient (đạo hàm) được gọi là **first-order methods**. Nếu sử dụng đến hessian (đạo hàm bậc hai) được gọi là **second-order methods**. Cũng còn các phương pháp không sử dụng đến đạo hàm mà chỉ sử dụng đến hàm số được tối ưu được gọi là **zero-order methods**. First-order methods được ưa chuộng trong machine learning bởi vì chúng có độ phức tạp thấp hơn second-order methods nhưng lại tối ưu nhanh hơn zero-order methods.\n",
    "\n",
    "**Gradient** là một *hàm trả về một vector*. Gradient của hàm $f$ theo $x$ kí hiệu là $\\nabla_x f$. Mình tạm kí hiệu $g(x) = \\nabla_x f $ để bạn đọc dễ nhìn ra đây là một hàm số. Gradient được tính bằng các công thức giống như tính đạo hàm một biến vậy nhưng áp dụng trên matrx hoặc tensor. Tuy nhiên, trong các framework deep learning hiện đại, gradient đều được tính tự động. \n",
    "\n",
    "**Nâng cao**: Kích thước (size) của gradient lúc nào cũng bằng với chiều của tham số được tính gradient theo. Ví dụ, nếu $x$ là vector 4 chiều thì gradient (theo $x$) trả về vector 4 chiều. Nếu $x$ là tensor $m \\times n \\times k$ thì gradient trả về tensor $m \\times n \\times k$. Mặc dù thật sự \"gradient\" lúc này không còn là gradient nữa (vì theo định nghĩa gradient chỉ trả về vector), nhưng với dân machine learning thì vẫn dùng từ \"gradient\" để chỉ \"*hàm trả về tensor cùng kích thước với tham số mà dịch chuyển tham số theo tensor đó làm hàm số tăng/giảm nhanh nhất*\".\n",
    "\n",
    "**Lưu ý**: dù gradient là một hàm số, khi văn cảnh rõ ràng, mình sẽ dùng từ \"gradient\" để chỉ cho giá trị của hàm gradient tại một điểm nào đó của hàm số. Bạn cũng sẽ bắt gặp cách dùng này trong nhiều tài liệu khác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tính chất của gradient\n",
    "\n",
    "Tính chất ta quan tâm nhất về gradient đó là : **tại điểm $x = x_0$ nào đó, khi ta dịch chuyển $x_0$ theo hướng của $g(x_0)$ sẽ làm cho $f(x_0)$ tăng nhanh nhất**. Nói đơn giản hơn là:\n",
    "$$ f(x + \\alpha g(x)) \\geq f(x) $$ với $\\alpha$ là một hằng số dương đủ nhỏ. \n",
    "\n",
    "Tuy nhiên trong machine learning ta thường quan tâm đến việc *giảm* hơn là tăng hàm số. Vì thế ta thường đi ngược chiều với gradient:\n",
    "$$ f(x - \\alpha g(x)) \\leq f(x) $$ \n",
    "\n",
    "**Câu hỏi**: *Tại sao đi ngược chiều gradient lại chắc chắn không tăng hàm số? Gợi ý: sử dụng tính chất $\\nabla_x [-f] = -\\nabla_x f$.*\n",
    "\n",
    "Nếu $f(x^*)$ là điểm cực tiểu, hiển nhiên dịch chuyển hướng nào cũng làm tăng hàm số. Cho nên:\n",
    "$$ f(x^* - \\alpha g(x^*)) \\geq f(x^*)$$\n",
    "\n",
    "Kết hợp với tính chất của gradient, ta được:\n",
    "$$ f(x^* - \\alpha g(x^*)) = f(x^*)$$ \n",
    "vì *gradient tại điểm cực tiểu bằng vector 0*: \n",
    "$$g(x^*) = \\vec{0}$$ \n",
    "Nói cách khác, khi hàm số đạt cực tiểu gradient sẽ bảo bạn ở yên đó và không đi đâu cả."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ví dụ minh họa bằng PyTorch\n",
    "\n",
    "Giả sử vector $x$ có 4 chiều $x = (x_1, x_2, x_3, x_4)$. Ta muốn tối ưu hàm số:\n",
    "\n",
    "$$ f(x) = x_1^2 + x_2^2 + x_3^2 + x_4^2 $$\n",
    "\n",
    "Ta biết bằng hàm này đạt cực tiểu bằng 0 khi $x = \\vec{0}$ nhưng hãy thử dùng iterative method để tìm nhé.\n",
    "\n",
    "Đầu tiên ta tạo ra $x$ ngẫu nhiên là tính giá trị của $f(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.6965\n",
      " 0.7130\n",
      " 0.2861\n",
      " 0.4285\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Đặt requires_grad=True để sau này tính đạo hàm.\n",
    "x = Variable(torch.rand(4), requires_grad=True)\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.2588\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f = sum_i(x_i^2)\n",
    "f = (x*x).sum()\n",
    "print f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ ta tính đạo hàm của $f$ theo $x$. Trong PyTorch, chỉ đơn giản gọi .backward()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.3929\n",
      " 1.4259\n",
      " 0.5723\n",
      " 0.8569\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f.backward()\n",
    "g = x.grad\n",
    "print g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu bạn nào rành về calculus thì biết rằng đạo hàm của $f(x)$ theo $x$ là $2x$. Kiểm chứng rằng $g$ đúng bằng $2x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 2*x - g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Điều gì xảy ra nếu ta đi theo hướng của gradient. Hãy kiểm tra giá trị $f(x - g)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.2588\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_new = x - g\n",
    "f_new = (x_new*x_new).sum()\n",
    "print f_new\n",
    "# Tính xem hàm số giảm được bao nhiêu so với giá trị cũ.\n",
    "print f_new - f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thật kì lạ là hàm số không hề giảm mặc dù ta biết rõ rằng $f$ không phải đang ở vị trí cực tiểu vì $x \\neq \\vec{0}$. \n",
    "\n",
    "Vấn đề ở đây là ta đã chọn một $\\alpha$ *quá lớn* ($\\alpha = 1$). Ở đây, $x$ sẽ chỉ đổi dấu sau mỗi lần cập nhật như vậy ($x \\rightarrow -x$). \n",
    "\n",
    "Tệ hơn nữa, nếu đặt $\\alpha = 2$ thì hàm số có khả năng **diverge**, tức là sẽ lớn dần lên. Để thuận tiện ra định nghĩa một hàm để cập nhật hàm số."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 11.3295\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 10.0707\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def eval(alpha):\n",
    "    x_new = x - alpha * g\n",
    "    f_new = (x_new*x_new).sum()\n",
    "    print f_new\n",
    "    print f_new - f\n",
    "\n",
    "eval(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy thử với một $\\alpha$ thật nhỏ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.3147\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "-0.9441\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm số đã giảm rồi! Ta thấy $\\alpha$ đóng vai trò cực kì quan trọng trong việc tối ưu hàm số. Với hàm $f$ này, tồn tại một $\\alpha$ tối ưu khiến cho hàm số lập tức dịch chuyển về cực tiểu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "-1.2588\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ này có thể được mô phỏng bằng hình vẽ 2 chiều sau:\n",
    "\n",
    "<img src=\"https://github.com/khanhptnk/deeplearning-tutorials/raw/master/images/5_gradient/example.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "Các thuật toán gradient descent (GD) đơn giản là việc lặp lại nhiều lần bước dịch chuyển tham số theo ngược chiều gradient, cũng chính là phương trình ở đầu bài. Tuy nhiên, mình thay hàm $L$ thành hàm $f_{\\theta}$ bất kì. \n",
    "\n",
    "$$ \\theta_{new} = \\theta_{old} - \\alpha \\nabla_{\\theta} f_{\\theta}$$ với $\\alpha$ được gọi là **learning rate** hoặc **step size**. \n",
    "\n",
    "Các thuật toán GD cơ bản khác nhau về cách cập nhật $\\alpha$ theo thời gian. Learning rate không nên quá lớn hoặc quá nhỏ:\n",
    "- Nếu quá lớn, hàm số có khả năng diverge.\n",
    "- Nếu quả nhỏ, hàm số converge (hội tụ) rất chậm. \n",
    "\n",
    "Theo cảm tính, chúng ta cần phải giảm dần $\\alpha$ vì càng gần điểm cực tiểu càng nhạy cảm, hàm số rất dễ diverge. \n",
    "\n",
    "Phiên bản đơn giản nhất của GD, để $\\alpha$ là một hằng số không đổi, không được sử dụng nhiều trong machine learning. Phiên bản cải tiến hơn thì sử dụng một cách thủ công nào đó để giảm $\\alpha$ theo thời gian, ví dụ $\\alpha_t = \\alpha_0 / (t + 1)$ với $t$ là số epoch. Các thuật toán adaptive GD hiện đại (AdaGrad, RMSProp, AdaDelta, Adam) tự động thay đổi $\\alpha$ một cách hợp lý. Tuy nhiên, theo kinh nghiệm thực tế, vẫn cần phải kết hợp chúng với việc giảm $\\alpha$ thủ công mới đạt hiệu quả cao nhất. \n",
    "\n",
    "**Câu hỏi**: *Khi nào cần giảm $\\alpha$? Gợi ý: khi [overfitting](https://ml-book-vn.khanhxnguyen.com/1_2_overfitting.html) xảy ra*.\n",
    "\n",
    "**Nâng cao**: GD không chắc chắn sẽ tìm ra được điểm cực tiểu của hàm số (global minimum), mà chỉ đảm bảo là nơi đó có gradient bằng 0. Bạn có thể hình dung việc tối ưu hàm số như là đi tìm thung lũng thấp nhất trong một vùng núi non. GD giống nhưng tổng lực của lực hấp dẫn và phản lực của mặt đất, sẽ kéo bạn lăn về nơi thấp hơn cho đến khi mặt đất không còn dốc nữa. Chỗ mặt đất không dốc có thể là (a) một trong nhiều thung lũng (local minimum) (b) cao nguyên (inflection point) (c) điểm yên ngựa (saddle point). \n",
    "\n",
    "\n",
    "<img src=\"https://github.com/khanhptnk/deeplearning-tutorials/raw/master/images/5_gradient/local.png\" width=\"33%\" align=\"left\"> \n",
    "\n",
    "<img src=\"https://github.com/khanhptnk/deeplearning-tutorials/raw/master/images/5_gradient/inflection.png\" width=\"33%\" align=\"left\">\n",
    "<figure>\n",
    "    <img src=\"https://github.com/khanhptnk/deeplearning-tutorials/raw/master/images/5_gradient/saddle.png\" width=\"33%\" align=\"left\">\n",
    "    <figcaption>Nguồn: <a href=\"https://en.wikipedia.org/wiki/Saddle_point\">Wikipedia</a></figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent\n",
    "\n",
    "Gradient có tính chất là nếu $f = \\sum_i f_i$ thì $\\nabla f = \\sum_i \\nabla f_i$ (đạo hàm của tổng bằng tổng đạo hàm). Vì thế nếu \n",
    "$f_{\\theta} = \\mathcal{L}(\\theta) = \\sum_{(x, y) \\in D_{train}} L(f_{\\theta}(x), y)$, thì\n",
    "\n",
    "$$\\nabla_{\\theta} f_{\\theta} = \\sum_{(x, y) \\in D_{train}} \\nabla_{\\theta} L(f_{\\theta}(x), y)$$\n",
    "\n",
    "Do đó, mỗi lần muốn tính $\\nabla_{\\theta} \\mathcal{L}(\\theta)$ thì ta phải lặp qua toàn bộ training set và tính gradient cho từng cặp $(x, y)$. Làm thế rất mất thời gian cho một lần cập nhật $\\theta$. Để cập nhật $\\theta$ nhanh hơn, ta chỉ tính gradient cho các cặp $(x, y)$ trong một batch nhỏ để xấp xỉ gradient trên toàn set, tức là \n",
    "\n",
    "$$\\nabla_{\\theta} f_{\\theta} \\approx \\sum_{(x, y) \\in D_b} \\nabla_{\\theta} L(f_{\\theta}(x), y)$$ với $D_b$ là một batch của $D_{train}$ có batch size bằng $b$.\n",
    "\n",
    "Thuật toán xấp xỉ này gọi là \"stochastic gradient descent\". Mặc dù gradient này chỉ là xấp xỉ nhưng thực nghiệm cho thấy nó vẫn giúp model tiến bộ sau mỗi lần cập nhật. Tư tưởng của thuật toán này thật sự rất đơn giản: bạn muốn tính trung bình cộng của một đại lượng trên một dân số rất lớn (ví dụ tính trung bình chiều cao của người Việt Nam), bạn có thể xấp xỉ bằng cách sample (lấy mẫu) ra một tập dân số nhỏ rồi tính trung bình cộng trên đó; dĩ nhiên là làm một lần thì sẽ có sai số nhưng nếu sample nhiều lần thì sai số tự động sẽ triệt tiêu lẫn nhau. \n",
    "\n",
    "Ta cũng thấy là việc chia data thành batch ngoài việc giúp xấp xỉ đạo hàm trên toàn training set, còn giúp cho tính toán đạo hàm nhanh hơn bởi vì các cặp ví dụ trên cùng một batch sẽ được tính đạo hàm song song trên GPU (parallel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc thêm:\n",
    "\n",
    "Một số bài viết bằng tiếng Việt của blog \"Machine Learning cơ bản\":\n",
    "[Gradient descent 1](http://machinelearningcoban.com/2017/01/12/gradientdescent/)\n",
    "[Gradient descent 2](http://machinelearningcoban.com/2017/01/16/gradientdescent2/)\n",
    "[Multivarate Calculus](http://machinelearningcoban.com/math/#-dao-ham-cua-ham-nhieu-bien)\n",
    "\n",
    "So sánh giữa các phương pháp gradient descent của Sebastian Ruder: \n",
    "[An overview of gradient descent optimization algorithms](http://sebastianruder.com/optimizing-gradient-descent/)\n",
    "\n",
    "Cách tính đạo hàm tự động minh họa bởi Chris Olah:\n",
    "[Calculus on Computational Graphs: Backpropagation](http://colah.github.io/posts/2015-08-Backprop/)\n",
    "\n",
    "Adam, một trong những optimizer thịnh hành nhất trong giới deep learning:\n",
    "[ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION](https://arxiv.org/pdf/1412.6980.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
