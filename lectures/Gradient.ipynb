{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div style=\"text-align: center; font-size: 35px\">\n",
    "    <b>\n",
    "    Gradient descent\n",
    "    </b>\n",
    "</div>\n",
    "<br/> <br/> <br/>\n",
    "\n",
    "Feedback xin gửi về [page Machine Learners](https://www.facebook.com/mlearners/) hoặc [group Machine Learners](https://www.facebook.com/groups/485581088316769/). Xem các bài viết khác và download code tại [Github page](https://github.com/khanhptnk/deeplearning-tutorials/).\n",
    "\n",
    "Chào các bạn, trong [bài viết trước](khanhxnguyen.com/deep-learning-4/), mình đã giới thiệu sơ lược về cách thức huấn luyện một model deep learning. Cùng ôn lại tí nhé!\n",
    "\n",
    "Huấn luyện (training) gồm hai giai đoạn, forward và backward. Trong bước forward, ta tính loss function dựa vào dự đoán của model và label thật. Trong bước backward, ta tính gradient (đạo hàm) theo parameter $\\theta$ của model, và cập nhật chúng theo quy tắc:\n",
    "$$ \\theta_{new} = \\theta_{old} - \\alpha \\nabla_{\\theta} L$$ với $\\alpha$ là learning rate và $\\nabla_{\\theta}L$ ký hiệu đạo hàm theo $\\theta$ của loss function $L$.\n",
    "\n",
    "Các bạn có thắc mắc rằng bước backward này thật ra có ý nghĩa gì? Tại sao nó lại làm model chính xác hơn? Bài viết hôm nay sẽ trả lời cho câu hỏi đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mục đích của huấn luyện\n",
    "\n",
    "Mục đích của huấn luyện là làm cho model mắc ít sai sót nhất có thể. Vì model là một hàm số $f_{\\theta}$ có parameter là $\\theta$, theo ngôn ngữ toán học, mục đích này chính là **tìm ra tham số $\\theta^*$ tối ưu sao cho trung bình loss function trên training set là nhỏ nhất**:\n",
    "\n",
    "$$ \\theta^* = \\arg \\min_{\\theta} \\mathcal{L}(\\theta) = \\arg \\min_{\\theta} \\frac{1}{|D_{train}|} \\sum_{(x, y) \\in D_{train}} L(f_{\\theta}(x), y)$$ với $D_{train}$ là training set. Kí hiệu $|D_{train}|$ nghĩa là số phần tử của training set. \n",
    "\n",
    "$\\mathcal{L}(\\theta)$ được gọi là **objective function** (hàm mục tiêu).\n",
    "\n",
    "**Nâng cao**: để đơn giản hóa, mình đã bỏ bớt regularization trong hàm mục tiêu. Bạn có thể xem thêm về regularization [tại đây](https://ml-book-vn.khanhxnguyen.com/1_3_rlm.html).\n",
    "\n",
    "Bài toán này là một dạng của **function optimization** (tối ưu hàm số). Ở đây vì $\\theta$ không có điều kiện gì ràng buộc nên được gọi là **unconstrained optimization**. \n",
    "\n",
    "Nếu không có công thức trực tiếp cho $\\theta^*$, ta bắt buộc phải làm nhỏ dần $\\mathcal{L}(\\theta)$ qua nhiều bước. Ta bắt đầu với một $\\theta$ ngẫu nhiên, và tìm cách làm cho $\\theta$ càng ngày càng tiến gần tới giá trị tối ưu $\\theta^*$. Cách làm như vậy được gọi là một **iterative method**. Mỗi lần forward và backward chính là một bước biến đổi $\\theta$ để làm $\\mathcal{L}(\\theta)$ nhỏ dần đi.\n",
    "\n",
    "Nếu ai đã quen thuộc với **binary search** thì sẽ nhận ra thuật toán này cũng mang tư tưởng tương tự. Binary search thực chất là một dạng đặc biệt của function optimization với hàm được tối ưu chính là giá trị tuyệt đối giữa dự đoán hiện tại và giá trị cần tìm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient \n",
    "\n",
    "Có rất nhiều phương pháp  để tối ưu hàm số. Các phương pháp sử dụng gradient (đạo hàm) được gọi là **first-order methods**. Các phương pháp sử dụng đến hessian (đạo hàm bậc hai) thì được gọi là **second-order methods**. Các phương pháp không sử dụng đến đạo hàm mà chỉ sử dụng đến hàm số được tối ưu được gọi là **zero-order methods**. First-order methods được ưa chuộng trong machine learning bởi vì chúng có độ phức tạp thấp hơn second-order methods nhưng lại tối ưu nhanh hơn zero-order methods.\n",
    "\n",
    "**Gradient** là một *hàm trả về một vector*. Gradient của hàm $f$ theo $\\theta$ kí hiệu là $\\nabla_{\\theta} f$. Mình tạm kí hiệu $g(\\theta) = \\nabla_{\\theta} f $ cho ngắn gọn. Các bạn lưu ý là $\\theta$ ở hai ký hiệu có ý nghĩa khác nhau. Để tính gradient theo $\\theta$ tại một điểm $\\theta_0$ nào đó, ta áp dụng công thức tính gradient để tìm ra $g(\\theta)$ (là một hàm số), sau đó tính $g(\\theta_0)$ (lắp giá trị $\\theta = \\theta_0$ vào hàm này).\n",
    "\n",
    "Kích thước (size/shape) của giá trị trả về từ hàm gradient lúc nào cũng bằng với kích của parameter được tính gradient theo. Ví dụ, nếu $\\theta$ là vector 4 chiều thì gradient (theo $\\theta$) trả về vector 4 chiều. Nếu $\\theta$ là tensor $m \\times n \\times k$ thì gradient trả về tensor $m \\times n \\times k$. Các bạn nhớ kỹ tính chất này vì nó rất quan khi debug các chương trình deep learning. \n",
    "\n",
    "Gradient được tính bằng các công thức giống như tính đạo hàm một biến vậy nhưng áp dụng trên matrix hoặc tensor. Tuy nhiên, trong các framework deep learning hiện đại (Theano, Tensorflow, Chainer, Torch, PyTroch), gradient đều được tính tự động. \n",
    "\n",
    "**Nâng cao**: khi gradient không trả về vector mà trả về tensor (ma trận nhiều chiều), thật sự \"gradient\" lúc này không còn là gradient nữa (vì theo định nghĩa gradient chỉ trả về vector), nhưng với dân machine learning thì vẫn dùng từ \"gradient\" để chỉ \"*hàm trả về tensor cùng kích thước với parameter mà dịch chuyển parameter theo hướng của tensor đó làm hàm số tăng/giảm nhanh nhất*\". Cách hiểu này vẫn đúng vì các parameter dù có kích thước thế nào đều có thể được trải phẳng ra thành một vector (và máy tính thực sự biểu diễn tensor như vậy để tăng tốc bộ nhớ).\n",
    "\n",
    "**Lưu ý**: dù gradient là một hàm số, khi văn cảnh rõ ràng, mình sẽ dùng từ \"gradient\" để chỉ giá trị của hàm gradient tại một điểm nào đó của hàm số. Bạn cũng sẽ bắt gặp cách dùng này trong nhiều tài liệu khác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tính chất của gradient\n",
    "\n",
    "Tính chất ta quan tâm nhất về gradient đó là : **tại điểm $\\theta = \\theta_0$ nào đó, khi ta dịch chuyển $\\theta_0$ theo hướng của $g(\\theta_0)$ sẽ làm cho $f(\\theta_0)$ tăng nhanh nhất**. Nói đơn giản hơn là:\n",
    "$$ f(\\theta_0 + \\alpha g(\\theta_0)) \\geq f(\\theta_0) $$ với $\\alpha$ là một hằng số dương đủ nhỏ. \n",
    "\n",
    "Tuy nhiên trong machine learning ta thường quan tâm đến việc *giảm* hơn là tăng hàm số. Vì thế ta thường đi ngược chiều với gradient:\n",
    "$$ f(\\theta_0 - \\alpha g(\\theta_0)) \\leq f(\\theta_0) $$ \n",
    "\n",
    "**Câu hỏi**: *Tại sao đi ngược chiều gradient lại chắc chắn không tăng hàm số? Gợi ý: sử dụng tính chất $\\nabla_x [-f] = -\\nabla_x f$.*\n",
    "\n",
    "Nếu $f(\\theta^*)$ là điểm cực tiểu, hiển nhiên dịch chuyển hướng nào cũng làm tăng hàm số:\n",
    "$$ f(\\theta^* - \\alpha g(\\theta^*)) \\geq f(\\theta^*)$$\n",
    "\n",
    "Kết hợp với tính chất của gradient, ta được:\n",
    "$$ f(\\theta^* - \\alpha g(\\theta^*)) = f(\\theta^*)$$ \n",
    "\n",
    "Điều này được thỏa mãn vì *gradient tại điểm cực tiểu bằng vector 0*: \n",
    "$$g(\\theta^*) = \\vec{0}$$ \n",
    "\n",
    "Nói cách khác, khi hàm số đạt cực tiểu gradient sẽ bảo bạn ở yên đó và không đi đâu cả."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ví dụ minh họa bằng PyTorch\n",
    "\n",
    "[Cách cài đặt PyTorch](http://khanhxnguyen.com/deep-learning-3/).\n",
    "\n",
    "Giả sử vector $\\theta$ có 4 chiều $\\theta = (\\vartheta_1, \\vartheta_2, \\vartheta_3, \\vartheta_4)$. Ta muốn tối ưu hàm số:\n",
    "\n",
    "$$ f(\\theta) = \\vartheta_1^2 + \\vartheta_2^2 + \\vartheta_3^2 + \\vartheta_4^2 $$\n",
    "\n",
    "Ta biết bằng hàm này đạt cực tiểu bằng 0 khi $\\theta = \\vec{0}$ nhưng hãy thử dùng iterative method để tìm nhé.\n",
    "\n",
    "Đầu tiên ta tạo ra $\\theta$ ngẫu nhiên và tính giá trị của $f(\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.6965\n",
      " 0.7130\n",
      " 0.2861\n",
      " 0.4285\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Đặt requires_grad=True để sau này tính gradient.\n",
    "t = Variable(torch.rand(4), requires_grad=True)\n",
    "print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.2588\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f = sum_i(t_i^2)\n",
    "f = (t*t).sum()\n",
    "print f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ ta tính gradient của $f$ theo $\\theta$. Trong PyTorch, chỉ đơn giản gọi .backward(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.3929\n",
      " 1.4259\n",
      " 0.5723\n",
      " 0.8569\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f.backward()\n",
    "g = t.grad\n",
    "print g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn có chú ý rằng $g$ mang size 4, cùng size với $\\theta$? \n",
    "\n",
    "Tiếp theo, nếu bạn nào rành về calculus thì biết rằng, dựa vào công thức, gradient là $2 \\theta$. Kiểm chứng rằng $g(\\theta)$ đúng bằng $2 \\theta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 2*t - g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Điều gì xảy ra nếu ta đi theo hướng của gradient. Hãy kiểm tra giá trị $f(x - g)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New value:  1.25883769989\n",
      "Difference from old value (positive value means larger):  0.0\n"
     ]
    }
   ],
   "source": [
    "t_new = t - g\n",
    "f_new = (t_new*t_new).sum()\n",
    "print \"New value: \", f_new.data[0]\n",
    "# Tính xem hàm số giảm được bao nhiêu so với giá trị cũ.\n",
    "print \"Difference from old value (positive value means larger): \", (f_new - f).data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thật kì lạ là hàm số không hề giảm mặc dù ta biết rõ rằng $f$ không phải đang ở vị trí cực tiểu vì $\\theta \\neq \\vec{0}$. \n",
    "\n",
    "Nhớ lại tính chất của gradient đòi hỏi một $\\alpha$ đủ nhỏ. Ở đây, ta đã chọn một $\\alpha$ *quá lớn* ($\\alpha = 1$). Trong trường hợp này, $x$ sẽ chỉ đổi dấu sau mỗi lần cập nhật ($\\theta \\rightarrow -\\theta$). \n",
    "\n",
    "Tệ hơn nữa, nếu đặt $\\alpha = 2$ thì hàm số có khả năng **diverge**, tức là sẽ lớn dần lên. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New value:  11.3295383453\n",
      "Difference from old value (positive value means larger):  10.0707006454\n"
     ]
    }
   ],
   "source": [
    "def eval(alpha):\n",
    "    t_new = t - alpha * g\n",
    "    f_new = (t_new*t_new).sum()\n",
    "    print \"New value: \", f_new.data[0]\n",
    "    print \"Difference from old value (positive value means larger): \", (f_new - f).data[0]\n",
    "\n",
    "eval(alpha=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy thử với một $\\alpha$ thật nhỏ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New value:  0.314709424973\n",
      "Difference from old value (positive value means larger):  -0.944128274918\n"
     ]
    }
   ],
   "source": [
    "eval(alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm số đã giảm rồi! Ta thấy $\\alpha$ đóng vai trò cực kì quan trọng trong việc tối ưu hàm số. Với hàm $f$ này, tồn tại một $\\alpha$ tối ưu khiến cho hàm số lập tức dịch chuyển về cực tiểu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New value:  0.0\n",
      "Difference from old value (positive value means larger):  -1.25883769989\n"
     ]
    }
   ],
   "source": [
    "eval(alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ này có thể được mô phỏng bằng hình vẽ 2 chiều sau:\n",
    "\n",
    "<img src=\"https://github.com/khanhptnk/deeplearning-tutorials/raw/master/images/5_gradient/example.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "Các thuật toán **gradient descent** (GD) đơn giản là việc *lặp lại nhiều lần bước dịch chuyển parameter theo ngược chiều gradient*, cũng chính là phương trình ở đầu bài. Tuy nhiên, ta thay hàm $L$ thành hàm $f_{\\theta}$ bất kì. \n",
    "\n",
    "$$ \\theta_{new} = \\theta_{old} - \\alpha \\nabla_{\\theta} f_{\\theta}$$ với $\\alpha$ được gọi là **learning rate** hoặc **step size**. \n",
    "\n",
    "Các thuật toán GD cơ bản khác nhau về cách cập nhật $\\alpha$ theo thời gian. Learning rate không nên quá lớn hoặc quá nhỏ:\n",
    "- Nếu quá lớn, hàm số có khả năng diverge.\n",
    "- Nếu quả nhỏ, hàm số converge (hội tụ) rất chậm. \n",
    "\n",
    "Cần phải giảm dần $\\alpha$ vì càng gần điểm cực tiểu càng nhạy cảm, hàm số rất dễ diverge. \n",
    "\n",
    "Phiên bản đơn giản nhất của GD, để $\\alpha$ là một hằng số không đổi, không được sử dụng nhiều trong machine learning. Phiên bản cải tiến hơn sử dụng một cách thủ công nào đó để giảm $\\alpha$ theo thời gian, ví dụ $\\alpha_t = \\alpha_0 / (t + 1)$ với $t$ là số epoch. Các thuật toán adaptive GD hiện đại (AdaGrad, RMSProp, AdaDelta, Adam) tự động thay đổi $\\alpha$ một cách hợp lý. Tuy nhiên, theo kinh nghiệm thực tế, vẫn cần phải kết hợp chúng với việc giảm $\\alpha$ thủ công mới đạt hiệu quả cao nhất. \n",
    "\n",
    "**Câu hỏi**: *Khi nào cần giảm $\\alpha$? Tại sao? Gợi ý: khi [overfitting](https://ml-book-vn.khanhxnguyen.com/1_2_overfitting.html) xảy ra*.\n",
    "\n",
    "**Nâng cao**: GD không chắc chắn sẽ tìm ra được điểm cực tiểu của hàm số (global minimum), mà chỉ đảm bảo là nơi đó có gradient bằng 0. Bạn có thể hình dung việc tối ưu hàm số như là đi tìm thung lũng thấp nhất trong một vùng núi non. GD giống nhưng tổng lực của lực hấp dẫn và phản lực của mặt đất, sẽ kéo bạn lăn về nơi thấp hơn cho đến khi mặt đất không còn dốc nữa. Chỗ mặt đất không dốc có thể là (a) một trong nhiều thung lũng (local minimum) (b) cao nguyên (inflection point) (c) đỉnh núi ở chiều này nhưng là thung lũng ở chiều khác (saddle point). Các tiến bộ về GD cố gắng tìm cách vượt qua các \"cạm bẫy\" này.\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/khanhptnk/deeplearning-tutorials/raw/master/images/5_gradient/local.png\" width=\"33%\" align=\"left\"> \n",
    "\n",
    "<img src=\"https://github.com/khanhptnk/deeplearning-tutorials/raw/master/images/5_gradient/inflection.png\" width=\"33%\" align=\"left\">\n",
    "\n",
    "<img src=\"https://github.com/khanhptnk/deeplearning-tutorials/raw/master/images/5_gradient/saddle.png\" width=\"33%\" align=\"left\">\n",
    "\n",
    "Nguồn: <a href=\"https://en.wikipedia.org/wiki/Saddle_point\">Wikipedia</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent\n",
    "\n",
    "Gradient có tính chất là nếu $f = \\sum_i h_i$ thì $\\nabla f = \\sum_i \\nabla h_i$ (đạo hàm của tổng bằng tổng đạo hàm). Vì thế nếu \n",
    "\n",
    "$$f_{\\theta} = \\mathcal{L}(\\theta) = \\frac{1}{|D_{train}|} \\sum_{(x, y) \\in D_{train}} L(f_{\\theta}(x), y)$$\n",
    "\n",
    "thì\n",
    "\n",
    "$$\\nabla_{\\theta} f_{\\theta} = \\frac{1}{|D_{train}|} \\sum_{(x, y) \\in D_{train}} \\nabla_{\\theta} L(f_{\\theta}(x), y)$$\n",
    "\n",
    "Do đó, mỗi lần muốn tính $\\nabla_{\\theta} \\mathcal{L}(\\theta)$ thì ta phải *lặp qua toàn bộ training set* và tính gradient cho từng cặp $(x, y)$. Làm thế rất mất thời gian cho một lần cập nhật $\\theta$. Để cập nhật $\\theta$ nhanh hơn, ta chỉ tính gradient cho các cặp $(x, y)$ trong một batch nhỏ để xấp xỉ gradient trên toàn set, tức là \n",
    "\n",
    "$$\\nabla_{\\theta} f_{\\theta} \\approx \\frac{1}{|D_b|} \\sum_{(x, y) \\in D_b} \\nabla_{\\theta} L(f_{\\theta}(x), y)$$ với $D_b$ là một batch của $D_{train}$ có batch size bằng $b$.\n",
    "\n",
    "Thuật toán xấp xỉ này gọi là **stochastic gradient descent**. Mặc dù gradient này chỉ là xấp xỉ nhưng thực nghiệm cho thấy nó vẫn giúp model tiến bộ sau mỗi lần cập nhật. \n",
    "\n",
    "Tư tưởng của thuật toán này thật sự rất đơn giản: bạn muốn tính trung bình cộng của một đại lượng trên một dân số rất lớn (ví dụ tính trung bình chiều cao của người Việt Nam), bạn có thể xấp xỉ bằng cách sample (lấy mẫu) ra một tập dân số nhỏ rồi tính trung bình cộng trên đó; dĩ nhiên là làm một lần thì sẽ có sai số nhưng nếu sample nhiều lần thì sai số tự động sẽ triệt tiêu lẫn nhau. Nếu bạn nghe đến thuật toán nào có chữ \"stochastic\" là sẽ có liên quan đến \"random sample\".\n",
    "\n",
    "Ta cũng thấy là việc chia data thành batch ngoài việc giúp xấp xỉ đạo hàm trên toàn training set, còn giúp cho tính toán đạo hàm nhanh hơn bởi vì các cặp ví dụ trên cùng một batch sẽ được tính đạo hàm song song trên GPU (parallel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc thêm:\n",
    "\n",
    "Một số bài viết bằng tiếng Việt của blog \"Machine Learning cơ bản\":\n",
    "[Gradient descent 1](http://machinelearningcoban.com/2017/01/12/gradientdescent/)\n",
    "[Gradient descent 2](http://machinelearningcoban.com/2017/01/16/gradientdescent2/)\n",
    "[Multivariate Calculus](http://machinelearningcoban.com/math/#-dao-ham-cua-ham-nhieu-bien)\n",
    "\n",
    "So sánh giữa các phương pháp gradient descent của Sebastian Ruder: \n",
    "[An overview of gradient descent optimization algorithms](http://sebastianruder.com/optimizing-gradient-descent/)\n",
    "\n",
    "Cách tính đạo hàm tự động minh họa bởi Chris Olah:\n",
    "[Calculus on Computational Graphs: Backpropagation](http://colah.github.io/posts/2015-08-Backprop/)\n",
    "\n",
    "Adam, một trong những optimizer thịnh hành nhất trong giới deep learning:\n",
    "[ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION](https://arxiv.org/pdf/1412.6980.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bài tập:\n",
    "\n",
    "Tìm hiểu về linear function và giải thích tại sao gradient là một linear function? Vì bài sau mình sẽ nói về linear function. Chúc các bạn học vui vẻ nhé :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
